{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d9867a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:08:01.189596Z",
     "iopub.status.busy": "2024-11-30T14:08:01.189295Z",
     "iopub.status.idle": "2024-11-30T14:08:05.766464Z",
     "shell.execute_reply": "2024-11-30T14:08:05.765537Z"
    },
    "papermill": {
     "duration": 4.585434,
     "end_time": "2024-11-30T14:08:05.768455",
     "exception": false,
     "start_time": "2024-11-30T14:08:01.183021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image \n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34ca88",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ad2220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:08:05.781189Z",
     "iopub.status.busy": "2024-11-30T14:08:05.780389Z",
     "iopub.status.idle": "2024-11-30T14:08:06.503941Z",
     "shell.execute_reply": "2024-11-30T14:08:06.503009Z"
    },
    "papermill": {
     "duration": 0.731859,
     "end_time": "2024-11-30T14:08:06.506099",
     "exception": false,
     "start_time": "2024-11-30T14:08:05.774240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images_path = []\n",
    "train_images_label = []\n",
    "label2id = {'Honda': 0, 'Others': 1, 'Suzuki': 2, 'VinFast': 3, 'Yamaha': 4}\n",
    "id2label = {0: 'Honda', 1: 'Others', 2: 'Suzuki', 3: 'VinFast', 4: 'Yamaha'}\n",
    "train_dir = '/kaggle/input/vn-moto-dataset'\n",
    "for subfolder in os.listdir(train_dir):\n",
    "    if not subfolder.endswith('.txt'):\n",
    "        for file in os.listdir(os.path.join(train_dir,subfolder)):\n",
    "            if file.lower().endswith('png') or file.lower().endswith('jpg') or file.lower().endswith('jpeg'):\n",
    "                train_images_path.append(os.path.join(train_dir,subfolder, file))\n",
    "                train_images_label.append(label2id[subfolder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdc27b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:08:06.520194Z",
     "iopub.status.busy": "2024-11-30T14:08:06.519331Z",
     "iopub.status.idle": "2024-11-30T14:09:21.638535Z",
     "shell.execute_reply": "2024-11-30T14:09:21.637707Z"
    },
    "papermill": {
     "duration": 75.127767,
     "end_time": "2024-11-30T14:09:21.640665",
     "exception": false,
     "start_time": "2024-11-30T14:08:06.512898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_valid_path = []\n",
    "train_valid_label = []\n",
    "for idx, path in enumerate(train_images_path):\n",
    "    img = Image.open(path)\n",
    "    if img.mode != \"P\":  # Exclude palette mode\n",
    "        train_valid_path.append(path)\n",
    "        train_valid_label.append(train_images_label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a791fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:21.653070Z",
     "iopub.status.busy": "2024-11-30T14:09:21.652817Z",
     "iopub.status.idle": "2024-11-30T14:09:21.882729Z",
     "shell.execute_reply": "2024-11-30T14:09:21.882104Z"
    },
    "papermill": {
     "duration": 0.237853,
     "end_time": "2024-11-30T14:09:21.884447",
     "exception": false,
     "start_time": "2024-11-30T14:09:21.646594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_images_path = []\n",
    "val_images_label = []\n",
    "val_dir = '/kaggle/input/tiny-moto-dataset'\n",
    "for subfolder in os.listdir(val_dir):\n",
    "    if not subfolder.endswith('.txt'):\n",
    "        for file in os.listdir(os.path.join(val_dir,subfolder)):\n",
    "            if file.lower().endswith('png') or file.lower().endswith('jpg') or file.lower().endswith('jpeg'):\n",
    "                val_images_path.append(os.path.join(val_dir,subfolder, file))\n",
    "                val_images_label.append(label2id[subfolder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc6bb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:21.896190Z",
     "iopub.status.busy": "2024-11-30T14:09:21.895930Z",
     "iopub.status.idle": "2024-11-30T14:09:26.898978Z",
     "shell.execute_reply": "2024-11-30T14:09:26.898259Z"
    },
    "papermill": {
     "duration": 5.011105,
     "end_time": "2024-11-30T14:09:26.901003",
     "exception": false,
     "start_time": "2024-11-30T14:09:21.889898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_valid_path = []\n",
    "val_valid_label = []\n",
    "for idx, path in enumerate(val_images_path):\n",
    "    img = Image.open(path)\n",
    "    if img.mode != \"P\":  # Exclude palette mode\n",
    "        val_valid_path.append(path)\n",
    "        val_valid_label.append(val_images_label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71a6759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:26.914838Z",
     "iopub.status.busy": "2024-11-30T14:09:26.914250Z",
     "iopub.status.idle": "2024-11-30T14:09:26.920144Z",
     "shell.execute_reply": "2024-11-30T14:09:26.919431Z"
    },
    "papermill": {
     "duration": 0.014315,
     "end_time": "2024-11-30T14:09:26.921728",
     "exception": false,
     "start_time": "2024-11-30T14:09:26.907413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, valid_images_path, images_label, transform = None):\n",
    "        self.valid_images_path = valid_images_path\n",
    "        self.images_label = images_label\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images_path)\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.valid_images_path[item]).convert(\"RGB\")\n",
    "        label = self.images_label[item]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "        \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        images, labels = tuple(zip(*batch))\n",
    "    \n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721742f",
   "metadata": {},
   "source": [
    "# ConvNeXt V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7007669a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:26.933500Z",
     "iopub.status.busy": "2024-11-30T14:09:26.933243Z",
     "iopub.status.idle": "2024-11-30T14:09:26.939130Z",
     "shell.execute_reply": "2024-11-30T14:09:26.938321Z"
    },
    "papermill": {
     "duration": 0.013553,
     "end_time": "2024-11-30T14:09:26.940715",
     "exception": false,
     "start_time": "2024-11-30T14:09:26.927162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bde08f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:26.952184Z",
     "iopub.status.busy": "2024-11-30T14:09:26.951939Z",
     "iopub.status.idle": "2024-11-30T14:09:26.958446Z",
     "shell.execute_reply": "2024-11-30T14:09:26.957798Z"
    },
    "papermill": {
     "duration": 0.013983,
     "end_time": "2024-11-30T14:09:26.959933",
     "exception": false,
     "start_time": "2024-11-30T14:09:26.945950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape), requires_grad=True)\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise ValueError(f\"not support data format '{self.data_format}'\")\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            # [batch_size, channels, height, width]\n",
    "            mean = x.mean(1, keepdim=True)\n",
    "            var = (x - mean).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68778ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:26.972744Z",
     "iopub.status.busy": "2024-11-30T14:09:26.972215Z",
     "iopub.status.idle": "2024-11-30T14:09:26.979491Z",
     "shell.execute_reply": "2024-11-30T14:09:26.978494Z"
    },
    "papermill": {
     "duration": 0.015564,
     "end_time": "2024-11-30T14:09:26.981059",
     "exception": false,
     "start_time": "2024-11-30T14:09:26.965495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GRN(nn.Module):\n",
    "    \"\"\" GRN (Global Response Normalization) layer\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Gx = torch.norm(x, p=2, dim=(1,2), keepdim=True)\n",
    "        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
    "        return self.gamma * (x * Nx) + self.beta + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57623ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:26.992755Z",
     "iopub.status.busy": "2024-11-30T14:09:26.992512Z",
     "iopub.status.idle": "2024-11-30T14:09:26.998613Z",
     "shell.execute_reply": "2024-11-30T14:09:26.997842Z"
    },
    "papermill": {
     "duration": 0.013781,
     "end_time": "2024-11-30T14:09:27.000226",
     "exception": false,
     "start_time": "2024-11-30T14:09:26.986445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" ConvNeXtV2 Block.\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.grn = GRN(4 * dim)\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.grn(x)\n",
    "        x = self.pwconv2(x)\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffb5abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.011988Z",
     "iopub.status.busy": "2024-11-30T14:09:27.011711Z",
     "iopub.status.idle": "2024-11-30T14:09:27.021817Z",
     "shell.execute_reply": "2024-11-30T14:09:27.021108Z"
    },
    "papermill": {
     "duration": 0.017944,
     "end_time": "2024-11-30T14:09:27.023326",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.005382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNeXtV2(nn.Module):\n",
    "    \"\"\" ConvNeXt V2\n",
    "        \n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], \n",
    "                 drop_path_rate=0., head_init_scale=1.\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j]) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f38022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.035045Z",
     "iopub.status.busy": "2024-11-30T14:09:27.034330Z",
     "iopub.status.idle": "2024-11-30T14:09:27.038135Z",
     "shell.execute_reply": "2024-11-30T14:09:27.037537Z"
    },
    "papermill": {
     "duration": 0.011227,
     "end_time": "2024-11-30T14:09:27.039676",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.028449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convnextv2_base(num_classes: int):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1893d27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.051739Z",
     "iopub.status.busy": "2024-11-30T14:09:27.051217Z",
     "iopub.status.idle": "2024-11-30T14:09:27.055000Z",
     "shell.execute_reply": "2024-11-30T14:09:27.054289Z"
    },
    "papermill": {
     "duration": 0.011481,
     "end_time": "2024-11-30T14:09:27.056556",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.045075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convnextv2_tiny(num_classes: int):\n",
    "    model = ConvNeXtV2(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744b060",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63ed83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.068242Z",
     "iopub.status.busy": "2024-11-30T14:09:27.067654Z",
     "iopub.status.idle": "2024-11-30T14:09:27.074400Z",
     "shell.execute_reply": "2024-11-30T14:09:27.073745Z"
    },
    "papermill": {
     "duration": 0.014137,
     "end_time": "2024-11-30T14:09:27.075872",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.061735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, lr_scheduler):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    accu_loss = torch.zeros(1).to(device)  \n",
    "    accu_num = torch.zeros(1).to(device)   \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        pred_classes = torch.max(pred, dim=1)[1]\n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        loss.backward()\n",
    "        accu_loss += loss.detach()\n",
    "\n",
    "        data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}, lr: {:.5f}\".format(\n",
    "            epoch,\n",
    "            accu_loss.item() / (step + 1),\n",
    "            accu_num.item() / sample_num,\n",
    "            optimizer.param_groups[0][\"lr\"]\n",
    "        )\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            print('WARNING: non-finite loss, ending training ', loss)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # update lr\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecfacc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.087368Z",
     "iopub.status.busy": "2024-11-30T14:09:27.087123Z",
     "iopub.status.idle": "2024-11-30T14:09:27.093089Z",
     "shell.execute_reply": "2024-11-30T14:09:27.092211Z"
    },
    "papermill": {
     "duration": 0.013624,
     "end_time": "2024-11-30T14:09:27.094614",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.080990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, epoch):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    accu_num = torch.zeros(1).to(device)   \n",
    "    accu_loss = torch.zeros(1).to(device)  \n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(data_loader):\n",
    "            images, labels = data\n",
    "            sample_num += images.shape[0]\n",
    "\n",
    "            pred = model(images.to(device))\n",
    "            pred_classes = torch.max(pred, dim=1)[1]\n",
    "            accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "\n",
    "            loss = loss_function(pred, labels.to(device))\n",
    "            accu_loss += loss\n",
    "\n",
    "            data_loader.desc = \"[valid epoch {}] loss: {:.3f}, acc: {:.3f}\".format(\n",
    "                epoch,\n",
    "                accu_loss.item() / (step + 1),\n",
    "                accu_num.item() / sample_num\n",
    "            )\n",
    "\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf9a54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.105944Z",
     "iopub.status.busy": "2024-11-30T14:09:27.105624Z",
     "iopub.status.idle": "2024-11-30T14:09:27.163123Z",
     "shell.execute_reply": "2024-11-30T14:09:27.162234Z"
    },
    "papermill": {
     "duration": 0.065118,
     "end_time": "2024-11-30T14:09:27.164905",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.099787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b42e7f",
   "metadata": {},
   "source": [
    "# Load pretrain FCMAE and fine tune for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77cbe5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:27.178391Z",
     "iopub.status.busy": "2024-11-30T14:09:27.178147Z",
     "iopub.status.idle": "2024-11-30T14:09:31.661881Z",
     "shell.execute_reply": "2024-11-30T14:09:31.661120Z"
    },
    "papermill": {
     "duration": 4.493519,
     "end_time": "2024-11-30T14:09:31.663911",
     "exception": false,
     "start_time": "2024-11-30T14:09:27.170392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1042762195.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weight_dict = torch.load('/kaggle/input/fcmae-pretrained/pre_last_model_50.pth', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = convnextv2_base(5).to(device)\n",
    "weight_dict = torch.load('/kaggle/input/fcmae-pretrained/pre_last_model_50.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17054bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.676295Z",
     "iopub.status.busy": "2024-11-30T14:09:31.676017Z",
     "iopub.status.idle": "2024-11-30T14:09:31.682490Z",
     "shell.execute_reply": "2024-11-30T14:09:31.681664Z"
    },
    "papermill": {
     "duration": 0.014476,
     "end_time": "2024-11-30T14:09:31.684172",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.669696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['mask_token', 'encoder.downsample_layers.0.0.weight', 'encoder.downsample_layers.0.0.bias', 'encoder.downsample_layers.0.1.weight', 'encoder.downsample_layers.0.1.bias', 'encoder.downsample_layers.1.0.weight', 'encoder.downsample_layers.1.0.bias', 'encoder.downsample_layers.1.1.weight', 'encoder.downsample_layers.1.1.bias', 'encoder.downsample_layers.2.0.weight', 'encoder.downsample_layers.2.0.bias', 'encoder.downsample_layers.2.1.weight', 'encoder.downsample_layers.2.1.bias', 'encoder.downsample_layers.3.0.weight', 'encoder.downsample_layers.3.0.bias', 'encoder.downsample_layers.3.1.weight', 'encoder.downsample_layers.3.1.bias', 'encoder.stages.0.0.dwconv.weight', 'encoder.stages.0.0.dwconv.bias', 'encoder.stages.0.0.norm.weight', 'encoder.stages.0.0.norm.bias', 'encoder.stages.0.0.pwconv1.weight', 'encoder.stages.0.0.pwconv1.bias', 'encoder.stages.0.0.pwconv2.weight', 'encoder.stages.0.0.pwconv2.bias', 'encoder.stages.0.0.grn.gamma', 'encoder.stages.0.0.grn.beta', 'encoder.stages.0.1.dwconv.weight', 'encoder.stages.0.1.dwconv.bias', 'encoder.stages.0.1.norm.weight', 'encoder.stages.0.1.norm.bias', 'encoder.stages.0.1.pwconv1.weight', 'encoder.stages.0.1.pwconv1.bias', 'encoder.stages.0.1.pwconv2.weight', 'encoder.stages.0.1.pwconv2.bias', 'encoder.stages.0.1.grn.gamma', 'encoder.stages.0.1.grn.beta', 'encoder.stages.0.2.dwconv.weight', 'encoder.stages.0.2.dwconv.bias', 'encoder.stages.0.2.norm.weight', 'encoder.stages.0.2.norm.bias', 'encoder.stages.0.2.pwconv1.weight', 'encoder.stages.0.2.pwconv1.bias', 'encoder.stages.0.2.pwconv2.weight', 'encoder.stages.0.2.pwconv2.bias', 'encoder.stages.0.2.grn.gamma', 'encoder.stages.0.2.grn.beta', 'encoder.stages.1.0.dwconv.weight', 'encoder.stages.1.0.dwconv.bias', 'encoder.stages.1.0.norm.weight', 'encoder.stages.1.0.norm.bias', 'encoder.stages.1.0.pwconv1.weight', 'encoder.stages.1.0.pwconv1.bias', 'encoder.stages.1.0.pwconv2.weight', 'encoder.stages.1.0.pwconv2.bias', 'encoder.stages.1.0.grn.gamma', 'encoder.stages.1.0.grn.beta', 'encoder.stages.1.1.dwconv.weight', 'encoder.stages.1.1.dwconv.bias', 'encoder.stages.1.1.norm.weight', 'encoder.stages.1.1.norm.bias', 'encoder.stages.1.1.pwconv1.weight', 'encoder.stages.1.1.pwconv1.bias', 'encoder.stages.1.1.pwconv2.weight', 'encoder.stages.1.1.pwconv2.bias', 'encoder.stages.1.1.grn.gamma', 'encoder.stages.1.1.grn.beta', 'encoder.stages.1.2.dwconv.weight', 'encoder.stages.1.2.dwconv.bias', 'encoder.stages.1.2.norm.weight', 'encoder.stages.1.2.norm.bias', 'encoder.stages.1.2.pwconv1.weight', 'encoder.stages.1.2.pwconv1.bias', 'encoder.stages.1.2.pwconv2.weight', 'encoder.stages.1.2.pwconv2.bias', 'encoder.stages.1.2.grn.gamma', 'encoder.stages.1.2.grn.beta', 'encoder.stages.2.0.dwconv.weight', 'encoder.stages.2.0.dwconv.bias', 'encoder.stages.2.0.norm.weight', 'encoder.stages.2.0.norm.bias', 'encoder.stages.2.0.pwconv1.weight', 'encoder.stages.2.0.pwconv1.bias', 'encoder.stages.2.0.pwconv2.weight', 'encoder.stages.2.0.pwconv2.bias', 'encoder.stages.2.0.grn.gamma', 'encoder.stages.2.0.grn.beta', 'encoder.stages.2.1.dwconv.weight', 'encoder.stages.2.1.dwconv.bias', 'encoder.stages.2.1.norm.weight', 'encoder.stages.2.1.norm.bias', 'encoder.stages.2.1.pwconv1.weight', 'encoder.stages.2.1.pwconv1.bias', 'encoder.stages.2.1.pwconv2.weight', 'encoder.stages.2.1.pwconv2.bias', 'encoder.stages.2.1.grn.gamma', 'encoder.stages.2.1.grn.beta', 'encoder.stages.2.2.dwconv.weight', 'encoder.stages.2.2.dwconv.bias', 'encoder.stages.2.2.norm.weight', 'encoder.stages.2.2.norm.bias', 'encoder.stages.2.2.pwconv1.weight', 'encoder.stages.2.2.pwconv1.bias', 'encoder.stages.2.2.pwconv2.weight', 'encoder.stages.2.2.pwconv2.bias', 'encoder.stages.2.2.grn.gamma', 'encoder.stages.2.2.grn.beta', 'encoder.stages.2.3.dwconv.weight', 'encoder.stages.2.3.dwconv.bias', 'encoder.stages.2.3.norm.weight', 'encoder.stages.2.3.norm.bias', 'encoder.stages.2.3.pwconv1.weight', 'encoder.stages.2.3.pwconv1.bias', 'encoder.stages.2.3.pwconv2.weight', 'encoder.stages.2.3.pwconv2.bias', 'encoder.stages.2.3.grn.gamma', 'encoder.stages.2.3.grn.beta', 'encoder.stages.2.4.dwconv.weight', 'encoder.stages.2.4.dwconv.bias', 'encoder.stages.2.4.norm.weight', 'encoder.stages.2.4.norm.bias', 'encoder.stages.2.4.pwconv1.weight', 'encoder.stages.2.4.pwconv1.bias', 'encoder.stages.2.4.pwconv2.weight', 'encoder.stages.2.4.pwconv2.bias', 'encoder.stages.2.4.grn.gamma', 'encoder.stages.2.4.grn.beta', 'encoder.stages.2.5.dwconv.weight', 'encoder.stages.2.5.dwconv.bias', 'encoder.stages.2.5.norm.weight', 'encoder.stages.2.5.norm.bias', 'encoder.stages.2.5.pwconv1.weight', 'encoder.stages.2.5.pwconv1.bias', 'encoder.stages.2.5.pwconv2.weight', 'encoder.stages.2.5.pwconv2.bias', 'encoder.stages.2.5.grn.gamma', 'encoder.stages.2.5.grn.beta', 'encoder.stages.2.6.dwconv.weight', 'encoder.stages.2.6.dwconv.bias', 'encoder.stages.2.6.norm.weight', 'encoder.stages.2.6.norm.bias', 'encoder.stages.2.6.pwconv1.weight', 'encoder.stages.2.6.pwconv1.bias', 'encoder.stages.2.6.pwconv2.weight', 'encoder.stages.2.6.pwconv2.bias', 'encoder.stages.2.6.grn.gamma', 'encoder.stages.2.6.grn.beta', 'encoder.stages.2.7.dwconv.weight', 'encoder.stages.2.7.dwconv.bias', 'encoder.stages.2.7.norm.weight', 'encoder.stages.2.7.norm.bias', 'encoder.stages.2.7.pwconv1.weight', 'encoder.stages.2.7.pwconv1.bias', 'encoder.stages.2.7.pwconv2.weight', 'encoder.stages.2.7.pwconv2.bias', 'encoder.stages.2.7.grn.gamma', 'encoder.stages.2.7.grn.beta', 'encoder.stages.2.8.dwconv.weight', 'encoder.stages.2.8.dwconv.bias', 'encoder.stages.2.8.norm.weight', 'encoder.stages.2.8.norm.bias', 'encoder.stages.2.8.pwconv1.weight', 'encoder.stages.2.8.pwconv1.bias', 'encoder.stages.2.8.pwconv2.weight', 'encoder.stages.2.8.pwconv2.bias', 'encoder.stages.2.8.grn.gamma', 'encoder.stages.2.8.grn.beta', 'encoder.stages.2.9.dwconv.weight', 'encoder.stages.2.9.dwconv.bias', 'encoder.stages.2.9.norm.weight', 'encoder.stages.2.9.norm.bias', 'encoder.stages.2.9.pwconv1.weight', 'encoder.stages.2.9.pwconv1.bias', 'encoder.stages.2.9.pwconv2.weight', 'encoder.stages.2.9.pwconv2.bias', 'encoder.stages.2.9.grn.gamma', 'encoder.stages.2.9.grn.beta', 'encoder.stages.2.10.dwconv.weight', 'encoder.stages.2.10.dwconv.bias', 'encoder.stages.2.10.norm.weight', 'encoder.stages.2.10.norm.bias', 'encoder.stages.2.10.pwconv1.weight', 'encoder.stages.2.10.pwconv1.bias', 'encoder.stages.2.10.pwconv2.weight', 'encoder.stages.2.10.pwconv2.bias', 'encoder.stages.2.10.grn.gamma', 'encoder.stages.2.10.grn.beta', 'encoder.stages.2.11.dwconv.weight', 'encoder.stages.2.11.dwconv.bias', 'encoder.stages.2.11.norm.weight', 'encoder.stages.2.11.norm.bias', 'encoder.stages.2.11.pwconv1.weight', 'encoder.stages.2.11.pwconv1.bias', 'encoder.stages.2.11.pwconv2.weight', 'encoder.stages.2.11.pwconv2.bias', 'encoder.stages.2.11.grn.gamma', 'encoder.stages.2.11.grn.beta', 'encoder.stages.2.12.dwconv.weight', 'encoder.stages.2.12.dwconv.bias', 'encoder.stages.2.12.norm.weight', 'encoder.stages.2.12.norm.bias', 'encoder.stages.2.12.pwconv1.weight', 'encoder.stages.2.12.pwconv1.bias', 'encoder.stages.2.12.pwconv2.weight', 'encoder.stages.2.12.pwconv2.bias', 'encoder.stages.2.12.grn.gamma', 'encoder.stages.2.12.grn.beta', 'encoder.stages.2.13.dwconv.weight', 'encoder.stages.2.13.dwconv.bias', 'encoder.stages.2.13.norm.weight', 'encoder.stages.2.13.norm.bias', 'encoder.stages.2.13.pwconv1.weight', 'encoder.stages.2.13.pwconv1.bias', 'encoder.stages.2.13.pwconv2.weight', 'encoder.stages.2.13.pwconv2.bias', 'encoder.stages.2.13.grn.gamma', 'encoder.stages.2.13.grn.beta', 'encoder.stages.2.14.dwconv.weight', 'encoder.stages.2.14.dwconv.bias', 'encoder.stages.2.14.norm.weight', 'encoder.stages.2.14.norm.bias', 'encoder.stages.2.14.pwconv1.weight', 'encoder.stages.2.14.pwconv1.bias', 'encoder.stages.2.14.pwconv2.weight', 'encoder.stages.2.14.pwconv2.bias', 'encoder.stages.2.14.grn.gamma', 'encoder.stages.2.14.grn.beta', 'encoder.stages.2.15.dwconv.weight', 'encoder.stages.2.15.dwconv.bias', 'encoder.stages.2.15.norm.weight', 'encoder.stages.2.15.norm.bias', 'encoder.stages.2.15.pwconv1.weight', 'encoder.stages.2.15.pwconv1.bias', 'encoder.stages.2.15.pwconv2.weight', 'encoder.stages.2.15.pwconv2.bias', 'encoder.stages.2.15.grn.gamma', 'encoder.stages.2.15.grn.beta', 'encoder.stages.2.16.dwconv.weight', 'encoder.stages.2.16.dwconv.bias', 'encoder.stages.2.16.norm.weight', 'encoder.stages.2.16.norm.bias', 'encoder.stages.2.16.pwconv1.weight', 'encoder.stages.2.16.pwconv1.bias', 'encoder.stages.2.16.pwconv2.weight', 'encoder.stages.2.16.pwconv2.bias', 'encoder.stages.2.16.grn.gamma', 'encoder.stages.2.16.grn.beta', 'encoder.stages.2.17.dwconv.weight', 'encoder.stages.2.17.dwconv.bias', 'encoder.stages.2.17.norm.weight', 'encoder.stages.2.17.norm.bias', 'encoder.stages.2.17.pwconv1.weight', 'encoder.stages.2.17.pwconv1.bias', 'encoder.stages.2.17.pwconv2.weight', 'encoder.stages.2.17.pwconv2.bias', 'encoder.stages.2.17.grn.gamma', 'encoder.stages.2.17.grn.beta', 'encoder.stages.2.18.dwconv.weight', 'encoder.stages.2.18.dwconv.bias', 'encoder.stages.2.18.norm.weight', 'encoder.stages.2.18.norm.bias', 'encoder.stages.2.18.pwconv1.weight', 'encoder.stages.2.18.pwconv1.bias', 'encoder.stages.2.18.pwconv2.weight', 'encoder.stages.2.18.pwconv2.bias', 'encoder.stages.2.18.grn.gamma', 'encoder.stages.2.18.grn.beta', 'encoder.stages.2.19.dwconv.weight', 'encoder.stages.2.19.dwconv.bias', 'encoder.stages.2.19.norm.weight', 'encoder.stages.2.19.norm.bias', 'encoder.stages.2.19.pwconv1.weight', 'encoder.stages.2.19.pwconv1.bias', 'encoder.stages.2.19.pwconv2.weight', 'encoder.stages.2.19.pwconv2.bias', 'encoder.stages.2.19.grn.gamma', 'encoder.stages.2.19.grn.beta', 'encoder.stages.2.20.dwconv.weight', 'encoder.stages.2.20.dwconv.bias', 'encoder.stages.2.20.norm.weight', 'encoder.stages.2.20.norm.bias', 'encoder.stages.2.20.pwconv1.weight', 'encoder.stages.2.20.pwconv1.bias', 'encoder.stages.2.20.pwconv2.weight', 'encoder.stages.2.20.pwconv2.bias', 'encoder.stages.2.20.grn.gamma', 'encoder.stages.2.20.grn.beta', 'encoder.stages.2.21.dwconv.weight', 'encoder.stages.2.21.dwconv.bias', 'encoder.stages.2.21.norm.weight', 'encoder.stages.2.21.norm.bias', 'encoder.stages.2.21.pwconv1.weight', 'encoder.stages.2.21.pwconv1.bias', 'encoder.stages.2.21.pwconv2.weight', 'encoder.stages.2.21.pwconv2.bias', 'encoder.stages.2.21.grn.gamma', 'encoder.stages.2.21.grn.beta', 'encoder.stages.2.22.dwconv.weight', 'encoder.stages.2.22.dwconv.bias', 'encoder.stages.2.22.norm.weight', 'encoder.stages.2.22.norm.bias', 'encoder.stages.2.22.pwconv1.weight', 'encoder.stages.2.22.pwconv1.bias', 'encoder.stages.2.22.pwconv2.weight', 'encoder.stages.2.22.pwconv2.bias', 'encoder.stages.2.22.grn.gamma', 'encoder.stages.2.22.grn.beta', 'encoder.stages.2.23.dwconv.weight', 'encoder.stages.2.23.dwconv.bias', 'encoder.stages.2.23.norm.weight', 'encoder.stages.2.23.norm.bias', 'encoder.stages.2.23.pwconv1.weight', 'encoder.stages.2.23.pwconv1.bias', 'encoder.stages.2.23.pwconv2.weight', 'encoder.stages.2.23.pwconv2.bias', 'encoder.stages.2.23.grn.gamma', 'encoder.stages.2.23.grn.beta', 'encoder.stages.2.24.dwconv.weight', 'encoder.stages.2.24.dwconv.bias', 'encoder.stages.2.24.norm.weight', 'encoder.stages.2.24.norm.bias', 'encoder.stages.2.24.pwconv1.weight', 'encoder.stages.2.24.pwconv1.bias', 'encoder.stages.2.24.pwconv2.weight', 'encoder.stages.2.24.pwconv2.bias', 'encoder.stages.2.24.grn.gamma', 'encoder.stages.2.24.grn.beta', 'encoder.stages.2.25.dwconv.weight', 'encoder.stages.2.25.dwconv.bias', 'encoder.stages.2.25.norm.weight', 'encoder.stages.2.25.norm.bias', 'encoder.stages.2.25.pwconv1.weight', 'encoder.stages.2.25.pwconv1.bias', 'encoder.stages.2.25.pwconv2.weight', 'encoder.stages.2.25.pwconv2.bias', 'encoder.stages.2.25.grn.gamma', 'encoder.stages.2.25.grn.beta', 'encoder.stages.2.26.dwconv.weight', 'encoder.stages.2.26.dwconv.bias', 'encoder.stages.2.26.norm.weight', 'encoder.stages.2.26.norm.bias', 'encoder.stages.2.26.pwconv1.weight', 'encoder.stages.2.26.pwconv1.bias', 'encoder.stages.2.26.pwconv2.weight', 'encoder.stages.2.26.pwconv2.bias', 'encoder.stages.2.26.grn.gamma', 'encoder.stages.2.26.grn.beta', 'encoder.stages.3.0.dwconv.weight', 'encoder.stages.3.0.dwconv.bias', 'encoder.stages.3.0.norm.weight', 'encoder.stages.3.0.norm.bias', 'encoder.stages.3.0.pwconv1.weight', 'encoder.stages.3.0.pwconv1.bias', 'encoder.stages.3.0.pwconv2.weight', 'encoder.stages.3.0.pwconv2.bias', 'encoder.stages.3.0.grn.gamma', 'encoder.stages.3.0.grn.beta', 'encoder.stages.3.1.dwconv.weight', 'encoder.stages.3.1.dwconv.bias', 'encoder.stages.3.1.norm.weight', 'encoder.stages.3.1.norm.bias', 'encoder.stages.3.1.pwconv1.weight', 'encoder.stages.3.1.pwconv1.bias', 'encoder.stages.3.1.pwconv2.weight', 'encoder.stages.3.1.pwconv2.bias', 'encoder.stages.3.1.grn.gamma', 'encoder.stages.3.1.grn.beta', 'encoder.stages.3.2.dwconv.weight', 'encoder.stages.3.2.dwconv.bias', 'encoder.stages.3.2.norm.weight', 'encoder.stages.3.2.norm.bias', 'encoder.stages.3.2.pwconv1.weight', 'encoder.stages.3.2.pwconv1.bias', 'encoder.stages.3.2.pwconv2.weight', 'encoder.stages.3.2.pwconv2.bias', 'encoder.stages.3.2.grn.gamma', 'encoder.stages.3.2.grn.beta', 'proj.weight', 'proj.bias', 'decoder.0.dwconv.weight', 'decoder.0.dwconv.bias', 'decoder.0.norm.weight', 'decoder.0.norm.bias', 'decoder.0.pwconv1.weight', 'decoder.0.pwconv1.bias', 'decoder.0.grn.gamma', 'decoder.0.grn.beta', 'decoder.0.pwconv2.weight', 'decoder.0.pwconv2.bias', 'pred.weight', 'pred.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc8ec8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.696273Z",
     "iopub.status.busy": "2024-11-30T14:09:31.696015Z",
     "iopub.status.idle": "2024-11-30T14:09:31.701136Z",
     "shell.execute_reply": "2024-11-30T14:09:31.700354Z"
    },
    "papermill": {
     "duration": 0.012834,
     "end_time": "2024-11-30T14:09:31.702697",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.689863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing key mask_token from pretrained checkpoint\n",
      "Removing key proj.weight from pretrained checkpoint\n",
      "Removing key proj.bias from pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.weight from pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.bias from pretrained checkpoint\n",
      "Removing key decoder.0.norm.weight from pretrained checkpoint\n",
      "Removing key decoder.0.norm.bias from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.weight from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.bias from pretrained checkpoint\n",
      "Removing key decoder.0.grn.gamma from pretrained checkpoint\n",
      "Removing key decoder.0.grn.beta from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.weight from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.bias from pretrained checkpoint\n",
      "Removing key pred.weight from pretrained checkpoint\n",
      "Removing key pred.bias from pretrained checkpoint\n"
     ]
    }
   ],
   "source": [
    "for k in list(weight_dict.keys()):\n",
    "    if 'decoder' in k or 'mask_token'in k or 'proj' in k or 'pred' in k:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del weight_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8008d1dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.714880Z",
     "iopub.status.busy": "2024-11-30T14:09:31.714614Z",
     "iopub.status.idle": "2024-11-30T14:09:31.718298Z",
     "shell.execute_reply": "2024-11-30T14:09:31.717519Z"
    },
    "papermill": {
     "duration": 0.011637,
     "end_time": "2024-11-30T14:09:31.719915",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.708278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_weight_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff5c2dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.731889Z",
     "iopub.status.busy": "2024-11-30T14:09:31.731638Z",
     "iopub.status.idle": "2024-11-30T14:09:31.735587Z",
     "shell.execute_reply": "2024-11-30T14:09:31.734908Z"
    },
    "papermill": {
     "duration": 0.011777,
     "end_time": "2024-11-30T14:09:31.737136",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.725359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,v in weight_dict.items():\n",
    "    if k.startswith(\"encoder.\"):\n",
    "        updated_weight_dict[k[len(\"encoder.\"):]]= v\n",
    "    else:\n",
    "        updated_weight_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f21b05e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.749008Z",
     "iopub.status.busy": "2024-11-30T14:09:31.748788Z",
     "iopub.status.idle": "2024-11-30T14:09:31.763937Z",
     "shell.execute_reply": "2024-11-30T14:09:31.763203Z"
    },
    "papermill": {
     "duration": 0.022813,
     "end_time": "2024-11-30T14:09:31.765489",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.742676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(updated_weight_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e704a909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.777754Z",
     "iopub.status.busy": "2024-11-30T14:09:31.777309Z",
     "iopub.status.idle": "2024-11-30T14:09:31.782895Z",
     "shell.execute_reply": "2024-11-30T14:09:31.782056Z"
    },
    "papermill": {
     "duration": 0.013455,
     "end_time": "2024-11-30T14:09:31.784499",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.771044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training head.weight\n",
      "training head.bias\n"
     ]
    }
   ],
   "source": [
    "for name, para in model.named_parameters():\n",
    "    if 'head' not in name:\n",
    "        para.requires_grad_(False)\n",
    "    else:\n",
    "        print(\"training {}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ff3e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.796735Z",
     "iopub.status.busy": "2024-11-30T14:09:31.796511Z",
     "iopub.status.idle": "2024-11-30T14:09:31.800116Z",
     "shell.execute_reply": "2024-11-30T14:09:31.799255Z"
    },
    "papermill": {
     "duration": 0.011735,
     "end_time": "2024-11-30T14:09:31.801841",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.790106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"./weights\") is False:\n",
    "    os.makedirs(\"./weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec48cf74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.813949Z",
     "iopub.status.busy": "2024-11-30T14:09:31.813689Z",
     "iopub.status.idle": "2024-11-30T14:09:31.818527Z",
     "shell.execute_reply": "2024-11-30T14:09:31.817817Z"
    },
    "papermill": {
     "duration": 0.01256,
     "end_time": "2024-11-30T14:09:31.820039",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.807479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "train_transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.CenterCrop(img_size),\n",
    "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "val_transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "train_dataset = MyDataset(train_valid_path, train_valid_label, train_transform)\n",
    "val_dataset = MyDataset(val_valid_path, val_valid_label, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70a5f33e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.832362Z",
     "iopub.status.busy": "2024-11-30T14:09:31.832149Z",
     "iopub.status.idle": "2024-11-30T14:09:31.836591Z",
     "shell.execute_reply": "2024-11-30T14:09:31.835907Z"
    },
    "papermill": {
     "duration": 0.012494,
     "end_time": "2024-11-30T14:09:31.838149",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.825655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       pin_memory=True,\n",
    "                       num_workers=nw,\n",
    "                       collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       pin_memory=True,\n",
    "                       num_workers=nw,\n",
    "                       collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0be808d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.867808Z",
     "iopub.status.busy": "2024-11-30T14:09:31.867559Z",
     "iopub.status.idle": "2024-11-30T14:09:31.873075Z",
     "shell.execute_reply": "2024-11-30T14:09:31.872335Z"
    },
    "papermill": {
     "duration": 0.013348,
     "end_time": "2024-11-30T14:09:31.874601",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.861253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lr_scheduler(optimizer,\n",
    "                        num_step: int,\n",
    "                        epochs: int,\n",
    "                        warmup=True,\n",
    "                        warmup_epochs=1,\n",
    "                        warmup_factor=1e-3,\n",
    "                        end_factor=1e-6):\n",
    "    assert num_step > 0 and epochs > 0\n",
    "    if warmup is False:\n",
    "        warmup_epochs = 0\n",
    "\n",
    "    def f(x):\n",
    "        if warmup is True and x <= (warmup_epochs * num_step):\n",
    "            alpha = float(x) / (warmup_epochs * num_step)\n",
    "            \n",
    "            return warmup_factor * (1 - alpha) + alpha\n",
    "        else:\n",
    "            current_step = (x - warmup_epochs * num_step)\n",
    "            cosine_steps = (epochs - warmup_epochs) * num_step\n",
    "            \n",
    "            return ((1 + math.cos(current_step * math.pi / cosine_steps)) / 2) * (1 - end_factor) + end_factor\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "684f696e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.886692Z",
     "iopub.status.busy": "2024-11-30T14:09:31.886473Z",
     "iopub.status.idle": "2024-11-30T14:09:31.891807Z",
     "shell.execute_reply": "2024-11-30T14:09:31.891017Z"
    },
    "papermill": {
     "duration": 0.013154,
     "end_time": "2024-11-30T14:09:31.893339",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.880185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                            lr=1e-3,\n",
    "                            weight_decay=1e-5)\n",
    "lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), epochs,\n",
    "                                   warmup=True, warmup_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c93e9ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T14:09:31.905425Z",
     "iopub.status.busy": "2024-11-30T14:09:31.905184Z",
     "iopub.status.idle": "2024-11-30T14:31:52.604126Z",
     "shell.execute_reply": "2024-11-30T14:31:52.603015Z"
    },
    "papermill": {
     "duration": 1340.707194,
     "end_time": "2024-11-30T14:31:52.606037",
     "exception": false,
     "start_time": "2024-11-30T14:09:31.898843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train epoch 0] loss: 1.382, acc: 0.416, lr: 0.00100: 100%|| 476/476 [02:06<00:00,  3.77it/s]\n",
      "[valid epoch 0] loss: 1.435, acc: 0.344: 100%|| 29/29 [00:08<00:00,  3.39it/s]\n",
      "[train epoch 1] loss: 1.240, acc: 0.497, lr: 0.00100: 100%|| 476/476 [02:06<00:00,  3.78it/s]\n",
      "[valid epoch 1] loss: 1.233, acc: 0.510: 100%|| 29/29 [00:08<00:00,  3.45it/s]\n",
      "[train epoch 2] loss: 1.198, acc: 0.518, lr: 0.00099: 100%|| 476/476 [02:05<00:00,  3.80it/s]\n",
      "[valid epoch 2] loss: 1.302, acc: 0.496: 100%|| 29/29 [00:08<00:00,  3.47it/s]\n",
      "Loss does not improve in 1 epochs!\n",
      "[train epoch 3] loss: 1.182, acc: 0.526, lr: 0.00097: 100%|| 476/476 [02:05<00:00,  3.81it/s]\n",
      "[valid epoch 3] loss: 1.243, acc: 0.504: 100%|| 29/29 [00:08<00:00,  3.43it/s]\n",
      "Loss does not improve in 2 epochs!\n",
      "[train epoch 4] loss: 1.156, acc: 0.536, lr: 0.00095: 100%|| 476/476 [02:05<00:00,  3.80it/s]\n",
      "[valid epoch 4] loss: 1.218, acc: 0.512: 100%|| 29/29 [00:08<00:00,  3.46it/s]\n",
      "[train epoch 5] loss: 1.151, acc: 0.537, lr: 0.00093: 100%|| 476/476 [02:05<00:00,  3.81it/s]\n",
      "[valid epoch 5] loss: 1.305, acc: 0.499: 100%|| 29/29 [00:08<00:00,  3.23it/s]\n",
      "Loss does not improve in 1 epochs!\n",
      "[train epoch 6] loss: 1.145, acc: 0.543, lr: 0.00090: 100%|| 476/476 [02:04<00:00,  3.81it/s]\n",
      "[valid epoch 6] loss: 1.266, acc: 0.463: 100%|| 29/29 [00:08<00:00,  3.47it/s]\n",
      "Loss does not improve in 2 epochs!\n",
      "[train epoch 7] loss: 1.136, acc: 0.546, lr: 0.00086: 100%|| 476/476 [02:05<00:00,  3.80it/s]\n",
      "[valid epoch 7] loss: 1.240, acc: 0.517: 100%|| 29/29 [00:08<00:00,  3.50it/s]\n",
      "Loss does not improve in 3 epochs!\n",
      "[train epoch 8] loss: 1.127, acc: 0.549, lr: 0.00082: 100%|| 476/476 [02:05<00:00,  3.80it/s]\n",
      "[valid epoch 8] loss: 1.249, acc: 0.528: 100%|| 29/29 [00:08<00:00,  3.45it/s]\n",
      "Loss does not improve in 4 epochs!\n",
      "[train epoch 9] loss: 1.119, acc: 0.552, lr: 0.00078: 100%|| 476/476 [02:05<00:00,  3.81it/s]\n",
      "[valid epoch 9] loss: 1.222, acc: 0.469: 100%|| 29/29 [00:08<00:00,  3.36it/s]\n",
      "Loss does not improve in 5 epochs. Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e9\n",
    "patience = 0\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    train_loss, train_acc = train_one_epoch(model=model,\n",
    "                                            optimizer=optimizer,\n",
    "                                            data_loader=train_loader,\n",
    "                                            device=device,\n",
    "                                            epoch=epoch,\n",
    "                                            lr_scheduler=lr_scheduler)\n",
    "\n",
    "    # validate\n",
    "    val_loss, val_acc = evaluate(model=model,\n",
    "                               data_loader=val_loader,\n",
    "                               device=device,\n",
    "                               epoch=epoch)\n",
    "    if best_loss >= val_loss:\n",
    "        torch.save(model.state_dict(), \"./weights/best_model.pth\")\n",
    "        best_loss = val_loss\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 5:\n",
    "            print(\"Loss does not improve in 5 epochs. Early Stopping!\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Loss does not improve in {patience} epochs!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6177636,
     "sourceId": 10031383,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6183251,
     "sourceId": 10038147,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6180911,
     "sourceId": 10059107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1445.134007,
   "end_time": "2024-11-30T14:31:54.742953",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-30T14:07:49.608946",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
